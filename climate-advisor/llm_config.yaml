# Climate Advisor LLM Configuration
# This file contains all LLM-related configuration for the Climate Advisor service

# Model Configuration
models:
  # Default model to use when none is specified
  default: "openai/gpt-4.1"

  # Available models with their capabilities and default parameters
  available:
    "openai/gpt-4.1":
      name: "GPT-4.1"
      default_temperature: 0.2

# Generation Parameters
generation:
  # Default parameters for text generation
  defaults:
    temperature: 0.1

# System Prompts
prompts:
  # Default system prompt for general climate advice
  default: "prompts/default.md"

  # Prompt for inventory-specific context
  inventory_context: "prompts/inventory_context.md"

  # Prompt for data analysis tasks
  data_analysis: "prompts/data_analysis.md"

# API Configuration
api:
  # OpenRouter configuration
  openrouter:
    base_url: "https://openrouter.ai/api/v1"
    # API key should be set via environment variable OPENROUTER_API_KEY
    timeout_ms: 30000
    retry_attempts: 3
    retry_delay_ms: 1000

  # OpenAI configuration for embeddings
  openai:
    base_url: "https://api.openai.com/v1"
    # API key should be set via environment variable OPENAI_API_KEY
    timeout_ms: 30000
    embedding_model: "text-embedding-3-large"

  # Request configuration
  requests:
    # Maximum time to wait for a response
    timeout_ms: 30000
    # Maximum number of retries for failed requests
    max_retries: 3
    # Delay between retries (exponential backoff)
    retry_delay_ms: 1000

# Tool Configuration
tools:
  # Climate Vector Search Tool
  climate_vector_search:
    enabled: true
    top_k: 3
    min_score: 0.6
    timeout_seconds: 20
    description: "Search the climate knowledge base for relevant information about climate change, emissions, GHG, carbon, sustainability, environmental policies, renewable energy, net zero goals, climate adaptation, and mitigation strategies."

# Conversation Configuration
conversation:
  # Number of previous messages to include for context
  history_limit: 5
  # Whether to include conversation history in agent context
  include_history: true

# Feature Flags
features:
  # Enable/disable streaming responses
  streaming_enabled: true

# Logging Configuration
logging:
  log_requests: true
  log_responses: true
  log_performance: true

# Observability Configuration
observability:
  langsmith:
    # Non-secret defaults for LangSmith integration
    project: "climate_advisor"
    endpoint: "https://api.smith.langchain.com"
    tracing_enabled: true
